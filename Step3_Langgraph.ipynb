{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8adbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/7gw2rnq56ls5m4r1vbglz5r00000gn/T/ipykernel_90852/1038369445.py:40: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily = TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "# How to connect with all teh different tools that Langchain Langgraph provides in Agent architectures\n",
    "# When there are multiple tools how LLM makes the choice on which tool to call\n",
    "# If there are needs to do multiple tool call - it will fail \n",
    "# Tools \n",
    "# - Wikipedia Search\n",
    "# - Google Search \n",
    "# - Research website ( Arxiv search)\n",
    "# - Web Search in using Tavily\n",
    "# - Add\n",
    "# - Multiply \n",
    "# Based on user question LLM will make the call\n",
    "\n",
    "# Created Wikipedia tool object \n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "print(wikipedia.description)\n",
    "\n",
    "\n",
    "# Created arxiv tool\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper = ArxivAPIWrapper())\n",
    "print(arxiv_tool.description)\n",
    "\n",
    "# tool for doing Web Searcg\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]= os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"]= os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]= os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]= os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]= os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "os.environ[\"TAVILY_API_KEY\"]= os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily = TavilySearchResults()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f2a548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: MS Dhoni\\nSummary: Mahendra Singh Dhoni ([məˈheːndrə ˈsɪŋɡʱ ˈdʱoːniː] ; born 7 July 1981) is an Indian professional cricketer who plays as a right-handed batter and a wicket-keeper. Widely regarded as one of the most prolific wicket-keeper batsmen and captains and one of the greatest ODI batsmen, he represented the Indian cricket team and was the captain of the side in limited overs formats from 2007 to 2017 and in test cricket from 2008 to 2014. Dhoni has captained the most international matches and is the most successful Indian captain. He has led India to victory in the 2007 ICC World Twenty20, the 2011 Cricket World Cup, and the 2013 ICC Champions Trophy, being the only captain to win three different limited overs ICC tournaments. He also led the teams that won the Asia Cup in 2010, 2016 and was a member of the title winning squad in 2018.\\nBorn in Ranchi, Dhoni made his first class debut for Bihar in 1999. He made his debut for the Indian cricket team on 23 December 2004 in an ODI against Bangladesh and played his first test a year later against Sri Lanka. In 2007, he became the captain of the ODI side before taking over in all formats by 2008. Dhoni retired from test cricket in 2014 but continued playing in limited overs cricket till 2019. He has scored 17,266 runs in international cricket including 10,000 plus runs at an average of more than 50 in ODIs.\\nIn the Indian Premier League (IPL), Dhoni plays for Chennai Super Kings (CSK), leading them to the final on ten occasions and winning it five times (2010, 2011, 2018, 2021 and 2023 ) jointly sharing this title with Rohit Sharma . He has also led CSK to two Champions League T20 titles in 2010 and 2014. Dhoni is among the few batsmen to have scored more than five thousand runs in the IPL, as well as being the first wicket-keeper to do so.\\nIn 2008, Dhoni was awarded India's highest sport honour Major Dhyan Chand Khel Ratna Award by Government of India. He received the fourth highest civilian award Padma Shri in 2009 and third highest civilian award Padma Bhushan in 2018. Dhoni holds an honorary rank of Lieutenant colonel in the Parachute Regiment of the Indian Territorial Army which was presented to him by the Indian Army in 2011. In June 2025, he was inducted into ICC Cricket Hall of Fame.\\n\\n\\n\\nPage: M.S. Dhoni: The Untold Story\\nSummary: M.S. Dhoni: The Untold Story is a 2016 Indian Hindi-language biographical sports drama film directed and co-written by Neeraj Pandey. It is based on the life of former Test, ODI and T20I captain of the Indian national cricket team, Mahendra Singh Dhoni. The film stars the late Sushant Singh Rajput as MS Dhoni, along with Disha Patani, Kiara Advani, and Anupam Kher. The film chronicles the life of Dhoni from a young age through a series of life events.\\nThe idea of the biopic was put forward by Dhoni's manager, Arun Pandey, after encountering an incident at an airport after the 2011 Cricket World Cup Final. Development began two years later, with the consent of Dhoni. Neeraj Pandey was later approached to helm the film while he was working on Baby. Pandey recruited a number of people for researching into Dhoni's background and his life events. Dhoni eventually became a consultant on the film.\\nThe film was released on 30 September 2016 by Fox Star Studios and received the widest release ever for a Bollywood film across 61 countries. In addition to being released in Hindi language, it was also dubbed in Tamil, Telugu, and Marathi languages, although the Marathi release was later cancelled due to opposition. Upon release, the film became a critical and commercial success. It is the fifth highest-grossing Bollywood film of 2016 and sixth highest grossing Indian film of 2016 worldwide ₹215.48 crore (US$25 million).\\n\\nPage: M.S. Dhoni: The Untold Story (soundtrack)\\nSummary: M.S. Dhoni: The Untold Story is the soundtrack album to the 2016 Hindi-language film of the same name directed by Neeraj Pandey. Based on the life of former Indian cricketer M\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.invoke(\"Who is MS Dhoni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e38d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2023-08-02\\nTitle: Attention Is All You Need\\nAuthors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\\nSummary: The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_tool.invoke(\"1706.03762\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce272b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-07-22\\nTitle: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\\nAuthors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\\nSummary: The inference demand for LLMs has skyrocketed in recent months, and serving\\nmodels with low latencies remains challenging due to the quadratic input length\\ncomplexity of the attention layers. In this work, we investigate the effect of\\ndropping MLP and attention layers at inference time on the performance of\\nLlama-v2 models. We find that dropping dreeper attention layers only marginally\\ndecreases performance but leads to the best speedups alongside dropping entire\\nlayers. For example, removing 33\\\\% of attention layers in a 13B Llama2 model\\nresults in a 1.8\\\\% drop in average performance over the OpenLLM benchmark. We\\nalso observe that skipping layers except the latter layers reduces performances\\nfor more layers skipped, except for skipping the attention layers.\\n\\nPublished: 2021-07-16\\nTitle: All the attention you need: Global-local, spatial-channel attention for image retrieval\\nAuthors: Chull Hwan Song, Hye Joo Han, Yannis Avrithis\\nSummary: We address representation learning for large-scale instance-level image\\nretrieval. Apart from backbone, training pipelines and loss functions, popular\\napproaches have focused on different spatial pooling and attention mechanisms,\\nwhich are at the core of learning a powerful global image representation. There\\nare different forms of attention according to the interaction of elements of\\nthe feature tensor (local and global) and the dimensions where it is applied\\n(spatial and channel). Unfortunately, each study addresses only one or two\\nforms of attention and applies it to different problems like classification,\\ndetection or retrieval.\\n  We present global-local attention module (GLAM), which is attached at the end\\nof a backbone network and incorporates all four forms of attention: local and\\nglobal, spatial and channel. We obtain a new feature tensor and, by spatial\\npooling, we learn a powerful embedding for image retrieval. Focusing on global\\ndescriptors, we provide empirical evidence of the interaction of all forms of\\nattention and improve the state of the art on standard benchmarks.\\n\\nPublished: 2023-06-02\\nTitle: RITA: Group Attention is All You Need for Timeseries Analytics\\nAuthors: Jiaming Liang, Lei Cao, Samuel Madden, Zachary Ives, Guoliang Li\\nSummary: Timeseries analytics is of great importance in many real-world applications.\\nRecently, the Transformer model, popular in natural language processing, has\\nbeen leveraged to learn high quality feature embeddings from timeseries, core\\nto the performance of various timeseries analytics tasks. However, the\\nquadratic time and space complexities limit Transformers' scalability,\\nespecially for long timeseries. To address these issues, we develop a\\ntimeseries analytics tool, RITA, which uses a novel attention mechanism, named\\ngroup attention, to address this scalability issue. Group attention dynamically\\nclusters the objects based on their similarity into a small number of groups\\nand approximately computes the attention at the coarse group granularity. It\\nthus significantly reduces the time and space complexity, yet provides a\\ntheoretical guarantee on the quality of the computed attention. The dynamic\\nscheduler of RITA continuously adapts the number of groups and the batch size\\nin the training process, ensuring group attention always uses the fewest groups\\nneeded to meet the approximation quality requirement. Extensive experiments on\\nvarious timeseries datasets and analytics tasks demonstrate that RITA\\noutperforms the state-of-the-art in accuracy and is significantly faster --\\nwith speedups of up to 63X.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_tool.invoke(\"Attention is all you need\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26da0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2015-09-01\\nTitle: A semiparametric scale-mixture regression model and predictive recursion maximum likelihood\\nAuthors: Ryan Martin, Zhen Han\\nSummary: To avoid specification of the error distribution in a regression model, we\\npropose a general nonparametric scale mixture model for the error distribution.\\nFor fitting such mixtures, the predictive recursion method is a simple and\\ncomputationally efficient alternative to existing methods. We define a\\npredictive recursion-based marginal likelihood function, and estimation of the\\nregression parameters proceeds by maximizing this function. A hybrid predictive\\nrecursion--EM algorithm is proposed for this purpose. The method's performance\\nis compared with that of existing methods in simulations and real data\\nanalyses.\\n\\nPublished: 2011-06-16\\nTitle: Semiparametric inference in mixture models with predictive recursion marginal likelihood\\nAuthors: Ryan Martin, Surya T. Tokdar\\nSummary: Predictive recursion is an accurate and computationally efficient algorithm\\nfor nonparametric estimation of mixing densities in mixture models. In\\nsemiparametric mixture models, however, the algorithm fails to account for any\\nuncertainty in the additional unknown structural parameter. As an alternative\\nto existing profile likelihood methods, we treat predictive recursion as a\\nfilter approximation to fitting a fully Bayes model, whereby an approximate\\nmarginal likelihood of the structural parameter emerges and can be used for\\ninference. We call this the predictive recursion marginal likelihood.\\nConvergence properties of predictive recursion under model mis-specification\\nalso lead to an attractive construction of this new procedure. We show\\npointwise convergence of a normalized version of this marginal likelihood\\nfunction. Simulations compare the performance of this new marginal likelihood\\napproach that of existing profile likelihood methods as well as Dirichlet\\nprocess mixtures in density estimation. Mixed-effects models and an empirical\\nBayes multiple testing application in time series analysis are also considered.\\n\\nPublished: 2021-10-06\\nTitle: Revisiting consistency of a recursive estimator of mixing distributions\\nAuthors: Vaidehi Dixit, Ryan Martin\\nSummary: Estimation of the mixing distribution under a general mixture model is a very\\ndifficult problem, especially when the mixing distribution is assumed to have a\\ndensity. Predictive recursion (PR) is a fast, recursive algorithm for\\nnonparametric estimation of a mixing distribution/density in general mixture\\nmodels. However, the existing PR consistency results make rather strong\\nassumptions, some of which fail for a class of mixture models relevant for\\nmonotone density estimation, namely, scale mixtures of uniform kernels. In this\\npaper, we develop new consistency results for PR under weaker conditions. Armed\\nwith this new theory, we prove that PR is consistent for the scale mixture of\\nuniforms problem, and we show that the corresponding PR mixture density\\nestimator has very good practical performance compared to several existing\\nmethods for monotone density estimation.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_tool.invoke(\"Mixture of Recursions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5894fc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Agentic AI - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Agentic_AI',\n",
       "  'content': 'Agentic AI is a class of artificial intelligence that focuses on autonomous systems that can make decisions and perform tasks without human intervention. The independent systems automatically respond to conditions, to produce process results. The field is closely linked to agentic automation, also known as agent-based process management systems, when applied to process automation. Applications include software development, customer support, cybersecurity and business intelligence. [...] The core concept of agentic AI is the use of _AI agents_ to perform automated tasks but without human intervention.( While robotic process automation (RPA) and AI agents can be programmed to automate specific tasks or support rule-based decisions, the rules are usually fixed.( Agentic AI operates independently, making decisions through continuous learning and analysis of external data and complex data sets.( Functioning agents can require various AI techniques, such as natural language',\n",
       "  'score': 0.95772696},\n",
       " {'title': 'What Is Agentic AI? | IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/agentic-ai',\n",
       "  'content': 'Agentic AI is an artificial intelligence system that can accomplish a specific goal with limited supervision. It consists of AI agents—machine learning models that mimic human decision-making to solve problems in real time. In a multiagent system, each agent performs a specific subtask required to reach the goal and their efforts are coordinated through AI orchestration. [...] Unlike traditional AI models, which operate within predefined constraints and require human intervention, agentic AI exhibits autonomy, goal-driven behavior and adaptability. The term “agentic” refers to these models’ agency, or, their capacity to act independently and purposefully.',\n",
       "  'score': 0.94796705},\n",
       " {'title': 'What is Agentic AI? | UiPath',\n",
       "  'url': 'https://www.uipath.com/ai/agentic-ai',\n",
       "  'content': \"Agentic AI is a probabilistic technology with high adaptability to changing environments and events. It relies on patterns and likelihoods to make decisions and take actions, as opposed to deterministic systems—such as Robotic Process Automation (RPA)—that follow fixed rules and predefined outcomes. Agentic AI now makes it possible to automate many workflows and business processes that deterministic systems have not been capable of addressing on their own. [...] Agentic AI, in short, is enabling us to create a new, virtual workforce that can, for the first time in history, complete the work of human knowledge workers. This opens up entirely new possibilities in designing work processes, deciding on the split of work between agents and people, and defining the roles of people and machines in myriad processes across the organization. [...] In essence, while GenAI focuses on creating, agentic AI focuses on doing. Generative AI's output is new content, while agentic AI's output is a series of actions or decisions. The two can be used in tandem to create powerful solutions that combine creativity with action. For example, a GenAI model could be used to create marketing copy, while an agentic AI system could autonomously deploy that copy to the optimal channels based on real-time data and campaign objectives.\",\n",
       "  'score': 0.9441409},\n",
       " {'title': 'What is Agentic AI? | Salesforce US',\n",
       "  'url': 'https://www.salesforce.com/agentforce/what-is-agentic-ai/',\n",
       "  'content': 'Agentic AI is the technology that powers AI agents so they can act autonomously without human oversight. By serving as a comprehensive platform, agentic AI facilitates seamless interaction between AI agents and humans, fostering a collaborative environment where both can work together. This platform has a suite of tools and services to help AI agents learn, adapt, and collaborate so they can quickly handle complex and dynamic tasks. It’s the next frontier of AI known for its ability to operate [...] ## What is agentic AI software?\\n\\nAgentic AI software is a type of artificial intelligence (AI) that can operate independently, making decisions and performing tasks without human intervention. These systems are able to learn from their interactions and adapt to new situations, improving their performance over time. [...] Agentic AI operates through a complex network of autonomous software components known as \"agents\" that draw from massive amounts of data and learn from user behavior to improve over time. Each agent is designed with specific goals and abilities, working in harmony to tackle complex tasks. This innovative approach to agentic AI relies on a blend of advanced technologies such as machine learning, NLP, and knowledge representation that helps agents learn, communicate, and reason effectively.',\n",
       "  'score': 0.9407083},\n",
       " {'title': 'Agentic AI vs. Generative AI - IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/agentic-ai-vs-generative-ai',\n",
       "  'content': 'Agentic AI describes AI systems that are designed to autonomously make decisions and act, with the ability to pursue complex goals with limited supervision. It brings together the flexible characteristics of large language models (LLMs) with the accuracy of traditional programming. This type of AI acts autonomously to achieve a goal by using technologies like natural language processing (NLPs), machine learning, reinforcement learning and knowledge representation. It’s a proactive AI-powered [...] Agentic AI is the broader concept of solving issues with limited supervision, whereas an AI agent is a specific component within that system that is designed to handle tasks and processes with a degree of autonomy. This model is changing the way humans interact with AI. The agentic AI system is able to understand the goal or vision of the user and uses the information that is provided to solve a problem. [...] It’s important to differentiate between agentic AI and AI agents. Essentially, agentic AI is the framework; AI agents are the building blocks within the framework.',\n",
       "  'score': 0.92763275}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.invoke(\"WHat is Agentic AI ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8329747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tools \n",
    "def my_add(a:int, b:int)-> int:\n",
    "    \"\"\"  Addition of a and b and not multiplication\n",
    "    Args:\n",
    "        a(int) : first int\n",
    "        b(int) : second int\n",
    "    Return:\n",
    "        int:\n",
    "    \"\"\"\n",
    "    return a+b\n",
    "\n",
    "def my_mult(a:int, b:int)-> int:\n",
    "    \"\"\" Multiplication of a and b and not addition. \n",
    "    Args:\n",
    "        a(int) : first int\n",
    "        b(int) : second int\n",
    "    Return:\n",
    "        int:\n",
    "    \"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc5ab337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm_open = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "\n",
    "tools = [wikipedia,arxiv_tool,tavily,my_add,my_mult]\n",
    "llm_with_tools = llm_open.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b79a5989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the bot\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list,add_messages]\n",
    "\n",
    "# Node definitions\n",
    "def my_own_bot_with_tools(state: State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "# Build graph\n",
    "from langgraph.graph import StateGraph, START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"my_own_bot_with_tools\",my_own_bot_with_tools)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "#Add edges\n",
    "# Edges\n",
    "builder.add_edge(START,\"my_own_bot_with_tools\")\n",
    "builder.add_conditional_edges(\"my_own_bot_with_tools\",tools_condition)\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "graph_builder = builder.compile()\n",
    "from IPython.display import Image,display\n",
    "display(Image(graph_builder.get_graph().draw_mermaid_png()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80d25870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Agentic AI?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (call_bZHE8DXS93WW0og8kbw9LKtk)\n",
      " Call ID: call_bZHE8DXS93WW0og8kbw9LKtk\n",
      "  Args:\n",
      "    query: Agentic AI\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: Agentic AI\n",
      "Summary: Agentic AI is a class of artificial intelligence that focuses on autonomous systems that can make decisions and perform tasks without human intervention. The independent systems automatically respond to conditions, to produce process results. The field is closely linked to agentic automation, also known as agent-based process management systems, when applied to process automation. Applications include software development, customer support, cybersecurity and business intelligence. \n",
      "\n",
      "\n",
      "\n",
      "Page: Intelligent agent\n",
      "Summary: In artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge. AI textbooks define artificial intelligence as the \"study and design of intelligent agents,\" emphasizing that goal-directed behavior is central to intelligence.\n",
      "A specialized subset of intelligent agents, agentic AI (also known as an AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods.\n",
      "Intelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.\n",
      "Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion. For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior. Similarly, an evolutionary algorithm's behavior is guided by a fitness function.\n",
      "Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\n",
      "Intelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".\n",
      "\n",
      "\n",
      "\n",
      "Page: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\n",
      "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
      "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "messages = graph_builder.invoke({\"messages\":\"What is Agentic AI?\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df279658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the recent news in US-India trade deal?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_KI4Kak6nIuwsgoLvvcKCjF30)\n",
      " Call ID: call_KI4Kak6nIuwsgoLvvcKCjF30\n",
      "  Args:\n",
      "    query: US India trade deal news\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Reciprocal Tariff Update: State of Bilateral Negotiations | Insights\", \"url\": \"https://www.hklaw.com/en/insights/publications/2025/07/reciprocal-tariff-update-state-of-bilateral-negotiations\", \"content\": \"IndiaNegotiations Ongoing: According to _Reuters,_ prospects for a U.S.-India interim trade deal before the Aug. 1, 2025, deadline have dimmed significantly, with sources citing persistent disagreements over tariff reductions and market access.July 22, 2025\", \"score\": 0.7746691}, {\"title\": \"India-U.S. trade deal: Deadlock over agri continues, but Trump ...\", \"url\": \"https://www.thehindu.com/news/national/india-us-trade-deal-deadlock-over-agri-continues-but-trump-surprise-not-ruled-out/article69842403.ece\", \"content\": \"Both sources confirmed that, while agriculture and dairy remain hurdles from the Indian side, a key hurdle from the U.S. side is their reluctance to reduce import duties on automotive components to zero.\\n\\nPublished - July 22, 2025 06:25 pm IST\\n\\n### Related Topics\\n\\nIndia-United States\\n/\\nIndia\\n/\\ndiplomacy\\n/\\ninternational relations\\n/\\ntrade policy\\n/\\ninternational (foreign) trade\\n/\\ntrade agreements\\n\\n### Top News Today\\n\\nReturn to frontpage\\nGoogle Play\\nApple Store\\n\\n##### The Hindu\\n\\n##### Contact us [...] ## Officials anticipate a surprise from President Trump in U.S.-India trade negotiations, with agriculture and automotive components as key issues\\n\\nUpdated  - July 22, 2025 06:32 pm IST - New Delhi [...] India’s negotiation points are now aimed at a broader Bilateral Trade Agreement (BTA) by September or October this year, rather than a ‘mini deal’ before August 1. Yet, the government is prepared for a surprise deal announced by U.S. President Donald Trump. File\\n| Photo Credit: Reuters\", \"score\": 0.767638}, {\"title\": \"India expects 'preferential' tariffs in trade deal with U.S. - CNBC\", \"url\": \"https://www.cnbc.com/2025/07/25/india-expects-preferential-tariffs-in-trade-deal-with-us-says-indias-commerce-minister-piyush-goyal.html\", \"content\": \"Livestream\\n\\nMenu\\n\\nInvesting trends\\n\\nIndia expects 'preferential' tariffs in a trade deal with U.S., says India's commerce minister\\n==============================================================================================\\n\\nPublished Thu, Jul 24 2025 8:01 PM EDT Updated Fri, Jul 25 2025 1:35 AM EDT\\n\\nImage 8: thumbnail\\n\\nGanesh Rao@in/rao-ganesh@_GaneshRao\\n\\nWATCH LIVE [...] Published Time: 2025-07-25T00:01:45+0000\\n\\nIndia expects 'preferential' tariffs in trade deal with U.S.: India's Piyush Goyal\\n\\n===============\\n\\nSkip Navigation\\n\\nImage 1: CNBC logo\\n\\nImage 2: logo\\n\\nMarkets\\n\\n   Pre-Markets\\n   U.S. Markets\\n   Currencies\\n   Cryptocurrency\\n   Futures & Commodities\\n   Bonds\\n   Funds & ETFs\\n\\nBusiness [...] Indian Prime Minister Narendra Modi. \\\"I have excellent relations with my good friend, [U.S.] Commerce Secretary, Mr Howard Lutnick,\\\" Goyal said. \\\"The United States and India share a very special relationship, and I'm very confident we'll do a robust and good deal where both countries benefit and where businesses on both sides are happy.\\\" Lutnick is leading the U.S. trade negotiating team. The optimism was echoed by business leaders, who predicted that while a deal would be reached, India would\", \"score\": 0.7213709}, {\"title\": \"India-US trade deal: What's holding back the agreement and risks of ...\", \"url\": \"https://www.livemint.com/market/stock-market-news/indiaus-trade-deal-whats-holding-back-the-agreement-and-risks-of-further-delays-explained-11753342384560.html\", \"content\": \"As the US signed trade deals with major economies, with the latest being Japan and the Philippines after inking deals with Indonesia and Vietnam, which are key economies in the Asia region, the discussion with India is still ongoing. Despite multiple rounds of negotiations, an official announcement continues to be delayed. [...] India-US trade deal: The Indian stock market is navigating rough terrain, in contrast to Western markets, particularly the US, which is hitting record highs as progress on trade deals with major partners has eased earlier investor concerns about rising inflation and its potential spillover effects on the world's largest economy. [...] Earlier, the potential deal was expected to be announced before July 09, after the White House and Trump himself stated that an agreement with India would be finalized. However, the White House is reportedly demanding greater access for agriculture, dairy, and genetically modified (GM) products, which is delaying the signing of the deal, a demand New Delhi is reportedly denying in order to protect farmers.\", \"score\": 0.6914979}, {\"title\": \"Most Deals Finished, Will Send '200 Tariff Letters,' Says Trump\", \"url\": \"https://www.ndtvprofit.com/economy-finance/india-us-trade-deal-news-live-tariff-threat-latest-updates-donald-trump-pm-modi-liveblog\", \"content\": \"Washington's agreement with Tokyo sets tariffs on the nation's imports at 15%, including for autos, which are by far the biggest component of the trade deficit between the countries.\\n\\n## Trade Deal Live: India's Latest FTA\\n\\nIndia on Thursday had signed a free trade agreement with the United Kingdom, in a move that would enhance market access for various products between the nations. [...] The agreement will significantly reduce import duties and improve market access for goods and services on both sides. India’s average tariff on UK products will fall from 15% to 3%, easing entry for British exporters of soft drinks, cosmetics, cars and medical devices. Indian exports will also benefit from duty-free or preferential access across nearly all tariff lines.\\n\\n## US Trade Deal Live: Trump Considering Rebate For Americans [...] ## US Trade Deal Live: Tariffs To Range Between 15% To 50%\\n\\n## US Trade Deal Live: Trump Says Most Trade Deals Finished Right Now\\n\\n## Trade Deal LIVE: 50-50 Odds Of EU-US Trade Deal, Says Trump\\n\\n## India-US Trade Deal LIVE: Most Tariff Letters Will Be Going Out By Friday\\n\\nNDTV\\nNDTV\\nget_in_touch\\n\\n###### Get In Touch\\n\\nEditorial Feedback\\nSubscription Queries\\nSales\\nFor Any Complaints\\n\\n###### NDTV Profit\\n\\n###### NDTV Profit\\n\\n###### Stay Updated\\n\\n###### Follow Us\\n\\nscanner\\n\\n###### DOWNLOAD THE APP\", \"score\": 0.6844544}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "messages = graph_builder.invoke({\"messages\":\"What is the recent news in US-India trade deal?\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87df4c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is teh attention is all you need paper all about?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (call_LsxdWbfZHJztN7CKuDJNloqv)\n",
      " Call ID: call_LsxdWbfZHJztN7CKuDJNloqv\n",
      "  Args:\n",
      "    query: Attention is All You Need\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: Attention Is All You Need\n",
      "Summary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence, and a main contributor to the AI boom, as the transformer approach has become the main architecture of a wide variety of AI, such as large language models. At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but the authors go further in the paper, foreseeing the technique's potential for other tasks like question answering and what is now known as multimodal generative AI.\n",
      "The paper's title is a reference to the song \"All You Need Is Love\" by the Beatles. The name \"Transformer\" was picked because Jakob Uszkoreit, one of the paper's authors, liked the sound of that word.\n",
      "An early design document was titled \"Transformers: Iterative Self-Attention and Processing for Various Tasks\", and included an illustration of six characters from the Transformers franchise. The team was named Team Transformer.\n",
      "Some early examples that the team tried their Transformer architecture on included English-to-German translation, generating Wikipedia articles on \"The Transformer\", and parsing. These convinced the team that the Transformer is a general purpose language model, and not just good for translation.\n",
      "As of 2025, the paper has been cited more than 173,000 times, placing it among top ten most-cited papers of the 21st century.\n",
      "\n",
      "Page: All You Need Is Kill\n",
      "Summary: All You Need Is Kill is a Japanese science fiction light novel by Hiroshi Sakurazaka with illustrations by Yoshitoshi Abe. The book was published in Japanese by Shueisha under their Super Dash Bunko imprint in December 2004, and was later released in English by Viz Media under their Haikasoru imprint. All You Need Is Kill follows a soldier named Keiji Kiriya, who, after dying in a battle with extraterrestrials, is caught in a time loop that makes him live the same day repeatedly, allowing Kiriya to improve his fighting skills.\n",
      "A manga adaptation, written by Ryosuke Takeuchi and illustrated by Takeshi Obata, was serialized in Shueisha's Weekly Young Jump magazine between January and May 2014 and was also published by Viz Media in its Weekly Shonen Jump magazine. In November 2014, the Viz translation was released in a collected edition that included the entire series. A separate graphic novel adaptation, written by Nick Mamatas and illustrated by Lee Ferguson, was released in North America in May 2014. A live-action film adaptation from director Doug Liman starring Tom Cruise and Emily Blunt, titled Edge of Tomorrow, was released in May 2014. The English-language film tie-in edition of the novel also uses this title. An anime film adaptation produced by Studio 4°C has been announced.\n",
      "The novel was Sakurazaka's breakthrough science fiction novel, earning wide praise from fellow novelists including Yasutaka Tsutsui and Chōhei Kanbayashi and was entered in contention for the Best Japanese Long Work in the 36th Seiun Awards in 2005.\n",
      "\n",
      "Page: Transformer (deep learning architecture)\n",
      "Summary: In deep learning, transformer is an architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \n",
      "Transformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term \n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "messages = graph_builder.invoke({\"messages\":\"What is teh attention is all you need paper all about?\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e55d39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you give me list of research paper on transformer architecture?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_TTtWSG2S6HcbLfvQUHetUINj)\n",
      " Call ID: call_TTtWSG2S6HcbLfvQUHetUINj\n",
      "  Args:\n",
      "    query: transformer architecture\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2023-08-22\n",
      "Title: TurboViT: Generating Fast Vision Transformers via Generative Architecture Search\n",
      "Authors: Alexander Wong, Saad Abbasi, Saeejith Nair\n",
      "Summary: Vision transformers have shown unprecedented levels of performance in\n",
      "tackling various visual perception tasks in recent years. However, the\n",
      "architectural and computational complexity of such network architectures have\n",
      "made them challenging to deploy in real-world applications with\n",
      "high-throughput, low-memory requirements. As such, there has been significant\n",
      "research recently on the design of efficient vision transformer architectures.\n",
      "In this study, we explore the generation of fast vision transformer\n",
      "architecture designs via generative architecture search (GAS) to achieve a\n",
      "strong balance between accuracy and architectural and computational efficiency.\n",
      "Through this generative architecture search process, we create TurboViT, a\n",
      "highly efficient hierarchical vision transformer architecture design that is\n",
      "generated around mask unit attention and Q-pooling design patterns. The\n",
      "resulting TurboViT architecture design achieves significantly lower\n",
      "architectural computational complexity (>2.47$\\times$ smaller than FasterViT-0\n",
      "while achieving same accuracy) and computational complexity (>3.4$\\times$ fewer\n",
      "FLOPs and 0.9% higher accuracy than MobileViT2-2.0) when compared to 10 other\n",
      "state-of-the-art efficient vision transformer network architecture designs\n",
      "within a similar range of accuracy on the ImageNet-1K dataset. Furthermore,\n",
      "TurboViT demonstrated strong inference latency and throughput in both\n",
      "low-latency and batch processing scenarios (>3.21$\\times$ lower latency and\n",
      ">3.18$\\times$ higher throughput compared to FasterViT-0 for low-latency\n",
      "scenario). These promising results demonstrate the efficacy of leveraging\n",
      "generative architecture search for generating efficient transformer\n",
      "architecture designs for high-throughput scenarios.\n",
      "\n",
      "Published: 2020-06-15\n",
      "Title: Differentiable Neural Architecture Transformation for Reproducible Architecture Improvement\n",
      "Authors: Do-Guk Kim, Heung-Chang Lee\n",
      "Summary: Recently, Neural Architecture Search (NAS) methods are introduced and show\n",
      "impressive performance on many benchmarks. Among those NAS studies, Neural\n",
      "Architecture Transformer (NAT) aims to improve the given neural architecture to\n",
      "have better performance while maintaining computational costs. However, NAT has\n",
      "limitations about a lack of reproducibility. In this paper, we propose\n",
      "differentiable neural architecture transformation that is reproducible and\n",
      "efficient. The proposed method shows stable performance on various\n",
      "architectures. Extensive reproducibility experiments on two datasets, i.e.,\n",
      "CIFAR-10 and Tiny Imagenet, present that the proposed method definitely\n",
      "outperforms NAT and be applicable to other models and datasets.\n",
      "\n",
      "Published: 2023-11-21\n",
      "Title: Interpretation of the Transformer and Improvement of the Extractor\n",
      "Authors: Zhe Chen\n",
      "Summary: It has been over six years since the Transformer architecture was put\n",
      "forward. Surprisingly, the vanilla Transformer architecture is still widely\n",
      "used today. One reason is that the lack of deep understanding and comprehensive\n",
      "interpretation of the Transformer architecture makes it more challenging to\n",
      "improve the Transformer architecture. In this paper, we first interpret the\n",
      "Transformer architecture comprehensively in plain words based on our\n",
      "understanding and experiences. The interpretations are further proved and\n",
      "verified. These interpretations also cover the Extractor, a family of drop-in\n",
      "replacements for the multi-head self-attention in the Transformer architecture.\n",
      "Then, we propose an improvement on a type of the Extractor that outperforms the\n",
      "self-attention, without introducing additional trainable parameters.\n",
      "Experimental results demonstrate that the improved Extractor performs even\n",
      "better, showing a way to improve the Transformer architecture.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "messages = graph_builder.invoke({\"messages\":\"Can you give me list of research paper on transformer architecture?\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd58000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the 10 multiplied by 20?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  my_mult (call_kMohLvm0Ar2xC7ieD9sAcmDL)\n",
      " Call ID: call_kMohLvm0Ar2xC7ieD9sAcmDL\n",
      "  Args:\n",
      "    a: 10\n",
      "    b: 20\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: my_mult\n",
      "\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "messages = graph_builder.invoke({\"messages\":\"What is the 10 multiplied by 20?\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac926a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
